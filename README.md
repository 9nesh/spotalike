# SpotaLike - AI-Powered Music Recommendation System ğŸµğŸ¶âœ¨

## Overview

SpotaLike is an AI-driven music recommendation system designed to personalize the listening experience. Using advanced machine learning techniques, the platform categorizes music based on mood and activity, allowing users to discover tracks that align with their emotions and current activities. The application leverages clustering, classification, and integration with streaming platforms to deliver tailored playlists. ğŸ§ğŸ¤ğŸ¹

---

## Features

- **Mood-Based Recommendations:** Classifies tracks into moods (e.g., Happy, Chill, Party) using clustering and supervised learning. ğŸ­
- **Activity-Based Recommendations:** Tailors playlists for activities (e.g., Workout, Study, Relaxation). ğŸ‹ï¸â€â™‚ï¸
- **Dimensionality Reduction:** Visualizes music data with PCA for insightful analysis. ğŸ“‰
- **Customizable UI:** A user-friendly Streamlit interface styled for an immersive experience. ğŸ¨
- **Explainable AI:** Highlights feature importance for transparency in recommendations. ğŸ’¡

---

## Project Structure ğŸ“

```plaintext
â”œâ”€â”€ app.py                 # Streamlit-based web application
â”œâ”€â”€ analyze_confusion.py   # Confusion matrix analysis for model evaluation
â”œâ”€â”€ pca.py                 # PCA-based visualization of mood and activity clustering
â”œâ”€â”€ train_model.py         # Training pipeline for mood and activity classifiers
â”œâ”€â”€ test_model.py          # Model evaluation with validation data
â”œâ”€â”€ visualize_model.py     # Visualization of model performance and feature importance
â”œâ”€â”€ random_forest.py       # Implementation of custom Random Forest classifier
â”œâ”€â”€ script.py              # Data preprocessing and unsupervised clustering
â”œâ”€â”€ training_data.csv      # Training dataset (generated by script.py)
â”œâ”€â”€ validation_data.csv    # Validation dataset for model testing
â”œâ”€â”€ viz/                   # Directory for PCA plots and text outputs
```

---

## Installation ğŸ’»ğŸ“¦

1. **Clone the Repository:**

   ```bash
   git clone https://github.com/username/SpotaLike.git
   cd SpotaLike
   ```

2. **Install Dependencies:**
   Ensure Python 3.8+ is installed, then run:

   ```bash
   pip install -r requirements.txt
   ```

3. **Prepare Data:**
   Ensure `data.csv` is available in the root directory for preprocessing and training. The `script.py` will generate `training_data.csv` and `validation_data.csv`. ğŸ“Š

---

## Usage ğŸš€

### 1. Preprocess Data

Run the preprocessing pipeline to cluster tracks and split the data:

```bash
python script.py
```

### 2. Train Models

Train mood and activity classifiers:

```bash
python train_model.py
```

### 3. Evaluate Models

Test the models using validation data:

```bash
python test_model.py
```

### 4. Visualize Results

Generate confusion matrices and feature importance plots:

```bash
python visualize_model.py
```

### 5. Launch the App

Start the Streamlit application:

```bash
streamlit run app.py
```

---

## Key Algorithms and Techniques ğŸ§ ğŸ’¾

### 1. Clustering

- **Algorithm Used:** K-Means clustering groups music tracks based on their feature similarities, such as `danceability`, `energy`, and `tempo`. ğŸ¯
- **Objective:** To identify distinct clusters of moods and activities without prior label information, enhancing personalization. ğŸ—‚ï¸
- **Implementation Details:**
  - **Feature Selection:** The clustering process uses key audio attributes like `danceability`, `energy`, `loudness`, `acousticness`, and `valence`.
  - **Cluster Types:**
    - Mood clusters: Tracks are grouped into five distinct emotional categories:
      - **Happy:** High energy and positive valence tracks suitable for uplifting moods.
      - **Sad:** Lower energy, often with minor keys, evoking introspective or melancholic feelings.
      - **Chill:** Relaxing tracks with mellow dynamics and soothing tones.
      - **Party:** Upbeat, danceable tracks with prominent rhythmic and tempo features.
      - **Relaxed:** Tracks characterized by calm energy and acoustic elements, ideal for unwinding. ğŸ‰
    - Activity clusters: Tracks are aligned with six activity-based scenarios:

1. **Workout:**

   - Tracks with high energy and a consistent beat.
   - Features include high tempo and rhythmic stability to sustain physical exertion.
   - Examples: Upbeat EDM, energetic rock.

2. **Study:**

   - Tracks designed to enhance focus and concentration.
   - Minimal vocals and steady dynamics.
   - Examples: Lo-fi beats, classical instrumental.

3. **Relaxation:**

   - Tracks aimed at reducing stress and promoting calmness.
   - Acoustic elements, low energy, and smooth transitions.
   - Examples: Soft jazz, ambient.

4. **Driving:**

   - Balanced tracks suitable for long commutes or road trips.
   - Mix of moderate energy and melodic structure.
   - Examples: Indie pop, classic rock.

5. **Party:**

   - Tracks with high tempo and strong rhythm for dancing.
   - Designed for social gatherings and high-energy environments.
   - Examples: Dance pop, club tracks.

6. **General:**

   - Tracks that are versatile and cater to casual, everyday listening.
   - Balanced energy levels with diverse genres.
   - Examples: Singer-songwriter playlists, acoustic pop. ğŸ¥³

- **Iterative Refinement:**
  - Initial clustering uses raw data.
  - Clusters are fine-tuned based on visualizations from PCA and domain knowledge. ğŸ”
- **Evaluation Metrics:**
  - Within-Cluster Sum of Squares (WCSS) to assess compactness.
  - Silhouette Score to evaluate separation between clusters.
- **Output:** Cluster labels assigned to each track, saved in the dataset for downstream tasks like classification. ğŸ“‚

### 2. Classification

- **Classifier Used:** Custom Random Forest classifiers are implemented for supervised prediction of moods and activities. ğŸŒ³
  - Each Random Forest is composed of multiple decision trees trained using bootstrap sampling and random feature selection.
  - The Random Forest aggregates predictions from individual trees to enhance robustness and accuracy. âœ…
- **Features Utilized:**
  - Key audio features, including `danceability`, `energy`, `valence`, `acousticness`, `speechiness`, `loudness`, and `tempo`.
  - Features are preprocessed using scaling, quantile transformations, and cyclical encoding for categorical features like `key`.
- **Training Details:**
  - **Labeled Datasets:** Training relies on manually labeled mood and activity categories derived from unsupervised clustering results.
  - **Parallelized Training:** Multiple trees are trained in parallel, leveraging multi-core CPU capabilities to accelerate computation. ğŸ’¨
  - **Feature Importance:** Outputs ranked feature importance metrics to identify the attributes most influential in prediction.
  - **Hyperparameters:** Configurable options include the number of trees, maximum depth, and minimum samples per split, tuned for optimal performance.
  - **Evaluation:** Models are validated using holdout datasets, with accuracy and F1 scores assessed across mood and activity categories. ğŸ“ˆ

### 3. Dimensionality Reduction

- **Technique Used:** Principal Component Analysis (PCA) reduces the dataset to two components for visualization. ğŸ¨
- **Visualization Goals:**
  - Highlight distinct clusters for moods and activities.
  - Use color-coding for easier interpretation of cluster separations.
  - Explained variance ratios provide insights into data spread.
- **Outputs:** PCA plots saved in the `viz/` directory for both mood and activity clusters. ğŸ–¼ï¸

### 4. Model Metrics

- **Evaluation Metrics:**
  - **Confusion Matrix:** Provides a visual representation of model accuracy across categories.
  - **Accuracy Score:** Measures overall correctness.
  - **F1 Score:** Captures a balance between precision and recall. ğŸ”„
- **Analysis Tools:**
  - Misclassification rates are calculated per category.
  - Top confusion pairs identify areas for model improvement. âš™ï¸

---

## Data Pipeline ğŸ› ï¸

1. **Preprocessing:** Scaling and transformation of features, including cyclical encoding for categorical data.
2. **Clustering:** Mood and activity clusters generated using K-Means.
3. **Labeling:** Mapped clusters to human-readable labels for supervised learning.
4. **Training:** Random Forest classifiers trained for mood and activity prediction.
5. **Evaluation:** Validation with accuracy, F1 scores, and confusion matrices. ğŸ“

---

## File Descriptions ğŸ“‚

- `app.py`: Implements a Streamlit-based interactive user interface.
- `analyze_confusion.py`: Analyzes confusion matrices for classifier errors.
- `pca.py`: Reduces data dimensions and visualizes clusters.
- `train_model.py`: Manages data transformation, training, and saving of classifiers.
- `test_model.py`: Tests trained classifiers and outputs evaluation metrics.
- `visualize_model.py`: Plots confusion matrices and feature importances.
- `random_forest.py`: Custom implementation of Random Forest for classification.
- `script.py`: Handles preprocessing, clustering, and dataset splitting. ğŸ“Š

---

## Future Enhancements ğŸ› ï¸âœ¨

- **Spotify API Integration:** Direct playlist creation and playback. ğŸµ
- **Hyperparameter Tuning:** Optimize classifier performance. ğŸ“ˆ
- **Real-Time Recommendations:** Adapt playlists based on real-time user feedback. ğŸ•’

---

## Contributors âœï¸

- **Inesh Tickoo**
- **Mostafa Anwari**
- **Nick Davis**

---

## License ğŸ“œ

This project is licensed under the MIT License. See `LICENSE` for details. ğŸ–‹ï¸

---

## Acknowledgments ğŸ™Œ

- Streamlit Documentation
- Scikit-learn
- Matplotlib and Seaborn for visualizations ğŸ‰

